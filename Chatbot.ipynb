{"cells":[{"cell_type":"markdown","metadata":{"id":"fsPbdaRS9hKt"},"source":["# Chatbot de recommandation de films"]},{"cell_type":"markdown","metadata":{"id":"FU2PUo459uTW"},"source":["## Import des bibliothèques"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G0dZJViA9LzV"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from google.colab import drive\n","from google.colab import output\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from scipy.sparse import vstack"]},{"cell_type":"markdown","metadata":{"id":"Tgx6HbnmQuGV"},"source":["## Création du Chatbot\n"]},{"cell_type":"markdown","metadata":{"id":"-eU_-j6hp2oN"},"source":["### Choix du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTLfTTuAp748","cellView":"form"},"outputs":[],"source":["#@markdown Choisissez un modèle de la liste suivante:\n","repo_id = \"gorkemgoknar/moviechatbot-mistral-v1\" # @param [\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\"gorkemgoknar/moviechatbot-mistral-v1\",\"mistralai/Mistral-7B-Instruct-v0.1\"]\n","\n","chatbot_repos = {\n","    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\": \"mistral-7b-instruct-v0.1.Q2_K.gguf\",\n","    \"gorkemgoknar/moviechatbot-mistral-v1\": \"mistral-moviechatbot-q5_K_M.gguf\"\n","}"]},{"cell_type":"markdown","metadata":{"id":"ZYeRYPfKs436"},"source":["#### Installation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109612,"status":"ok","timestamp":1702154083883,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"},"user_tz":-60},"id":"89OvUW7ls437","outputId":"b2a166ee-2d94-4150-e629-1f038c259cc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.2.20.tar.gz (8.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n","Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n","Building wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.20-cp310-cp310-manylinux_2_35_x86_64.whl size=7138286 sha256=e67264bafc185209f5f866380cc24d612b1e5d0b9fd64bd14c93ed9e95049934\n","  Stored in directory: /root/.cache/pip/wheels/ef/f2/d2/0becb03047a348d7bd9a5b91ec88f4654d6fa7d67ea4e84d43\n","Successfully built llama-cpp-python\n","Installing collected packages: llama-cpp-python\n","Successfully installed llama-cpp-python-0.2.20\n"]}],"source":["!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25257,"status":"ok","timestamp":1702154109317,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"},"user_tz":-60},"id":"_MRvC1eWs437","outputId":"be9d17d0-dfa5-4222-f612-2989633e810d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'llama.cpp'...\n","remote: Enumerating objects: 12959, done.\u001b[K\n","remote: Counting objects: 100% (3523/3523), done.\u001b[K\n","remote: Compressing objects: 100% (287/287), done.\u001b[K\n","remote: Total 12959 (delta 3367), reused 3291 (delta 3235), pack-reused 9436\u001b[K\n","Receiving objects: 100% (12959/12959), 15.46 MiB | 19.54 MiB/s, done.\n","Resolving deltas: 100% (9009/9009), done.\n","Collecting numpy==1.24.4 (from -r llama.cpp/requirements.txt (line 1))\n","  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece==0.1.98 (from -r llama.cpp/requirements.txt (line 2))\n","  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gguf>=0.1.0 (from -r llama.cpp/requirements.txt (line 3))\n","  Downloading gguf-0.5.1-py3-none-any.whl (23 kB)\n","Installing collected packages: sentencepiece, numpy, gguf\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gguf-0.5.1 numpy-1.24.4 sentencepiece-0.1.98\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["!git clone https://github.com/ggerganov/llama.cpp.git\n","!pip install -r llama.cpp/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17331,"status":"ok","timestamp":1702154126638,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"},"user_tz":-60},"id":"3OUq2O4Ys439","outputId":"af5950e0-6ced-4b21-f02d-419aa28cd6fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n","Collecting langchain\n","  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n","  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n","  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.24.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (3.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.11.17)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.2.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n","Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}],"source":["!pip install huggingface_hub langchain"]},{"cell_type":"markdown","metadata":{"id":"-uu_Oakos439"},"source":["#### Import du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3QWm2fIs439"},"outputs":[],"source":["if repo_id == \"mistralai/Mistral-7B-Instruct-v0.1\":\n","  from huggingface_hub import snapshot_download\n","  model_id=\"mistralai/Mistral-7B-Instruct-v0.1\"\n","  snapshot_download(repo_id=model_id, local_dir=\"mistral-hf\",\n","                  local_dir_use_symlinks=False, revision=\"main\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-RDEu3wrqwc","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["63f3348dafb84460a03558123c51d4e1","d891231cb5d5417d93a249efdc9830aa","9ba132accc0d46708dc215ce6617a76a","70573587594c4d1ca5d0db1bcd13fab1","13ae72d9df6c47339bd8f47196134c41","089c77e51122403493e87d503b1b15aa","11a0e9a8c6e240fe81015c4288199fb3","90ad1adec10d439ba0809cdc265660f5","5fdce08d340a4eaf940e5797a1203bb1","60bbe07ec81e422f97a71e55801de414","cecb38958359472f8aa7680588c14a2d"]},"executionInfo":{"status":"ok","timestamp":1702154176041,"user_tz":-60,"elapsed":49235,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"}},"outputId":"7dcbf576-1b9a-4e74-959f-b6c661be67be"},"outputs":[{"output_type":"display_data","data":{"text/plain":["mistral-moviechatbot-q5_K_M.gguf:   0%|          | 0.00/5.13G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63f3348dafb84460a03558123c51d4e1"}},"metadata":{}}],"source":["if repo_id != \"mistralai/Mistral-7B-Instruct-v0.1\":\n","  from huggingface_hub import hf_hub_download\n","  model_path = hf_hub_download(repo_id=repo_id, filename=chatbot_repos[repo_id])\n","else:\n","  model_path = \"artefact/model_llm.gguf\""]},{"cell_type":"markdown","metadata":{"id":"6eJCrwges43_"},"source":["#### Compression du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-XUPn_8fvvN"},"outputs":[],"source":["compression = \"f16\" # @param [\"f16\", \"q8_0\", \"f32\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONAC22UCs44A"},"outputs":[],"source":["if repo_id == \"mistralai/Mistral-7B-Instruct-v0.1\":\n","  !python llama.cpp/convert.py mistral-hf \\\n","    --outfile artefact/model_llm.gguf \\\n","    --outtype $compression"]},{"cell_type":"markdown","metadata":{"id":"iefBkZVks44A"},"source":["### Génération du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgPrbkrss44A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702154206492,"user_tz":-60,"elapsed":30485,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"}},"outputId":"3430781f-b2ea-4838-efaa-d615983552f7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! context_window is not default parameter.\n","                context_window was transferred to model_kwargs.\n","                Please confirm that context_window is what you intended.\n","  warnings.warn(\n","AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"]}],"source":["from langchain.llms import LlamaCpp\n","\n","llm = LlamaCpp(\n","  model_path=model_path,\n","  temperature=0.,\n","  max_tokens=200,\n","  top_p=1,\n","  n_gpu_layers = 100,    # number of layers loaded on the GPU\n","  verbose=True,          # necessary to load models, else provocate errors\n","  context_window=2000,\n",")"]},{"cell_type":"markdown","source":["### Prompts"],"metadata":{"id":"xQKYaHiFpaW1"}},{"cell_type":"code","source":["# This function uses a language model to determine if a given sentence is about a movie.\n","# It returns True if the sentence is about a movie, and False otherwise.\n","def sentence_about_movie(llm, sentence, verbose=0):\n","  question_pattern = \"\"\"\n","### Instruction ###\n","Answer 'Yes' if the following sentence is about movie, else 'No'.\n","\n","\"\"\"\n","  format = \"\\n### Response ###\\n\"\n","  response = llm(question_pattern+\"\\n'\"+sentence+\"'\\n\"+format)\n","  if verbose!=0:\n","    print(\"About movie: \", response)\n","  if response[0:2] == \"No\":\n","    return False\n","  return True\n","\n","# This function uses a language model to extract the name of the movie mentioned in a given sentence.\n","# If no movie name is mentioned, it returns 'NONE'\n","def extract_movie_name(llm, sentence, verbose=0):\n","  question_pattern = \"\"\"\n","### Instruction ###\n","Extract the name of the movie mentionned in the following sentence, else respond 'NONE'.\n","\n","\"\"\"\n","  format = \"\\n### Response ###\\n\"\n","  response = llm(question_pattern+\"\\n'\"+sentence+\"'\\n\"+format)\n","  if verbose!=0:\n","    print(\"Movie's name: \", response)\n","  return response"],"metadata":{"id":"rwcHhq3LpdHw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bcyK-2qz94dT"},"source":["## Import des données"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQBcQ9Dp_Bjk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702154251796,"user_tz":-60,"elapsed":45339,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"}},"outputId":"ec1d17ae-c8b7-4066-abd6-34bd011eaace"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Shareddrives/ING3 Projet NLP CY Tech 2023-2024\n"]}],"source":["# drive connection\n","drive.mount('/content/drive', force_remount=True)\n","\n","# path when the files are in a shared drive\n","path = '\"/content/drive/Shareddrives/ING3 Projet NLP CY Tech 2023-2024/\"'\n","\n","# move in directories\n","%cd $path"]},{"cell_type":"code","source":["def get_mpst_dataset():\n","  df = pd.read_csv(\"dataset/mpst_full_data.csv\", sep=\",\")\n","  return df\n","\n","def get_wiki_dataset():\n","  df_wiki = pd.read_csv(\"dataset/wiki_movie_plots_deduped.csv\")\n","  return df_wiki"],"metadata":{"id":"ifqoYvQHaV4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Choix de la base de données\n","\n","# @markdown Choisissez la base de données à utiliser parmi celles listées ci-dessous :\n","# @markdown - [`Wikipedia Movie Plots`](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots) , base de données de Wikipedia\n","# @markdown - `Cross dataset` , base de données générée par le croisement de  [Wikipedia Movie Plots](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots) et [MPST: Movie Plot Synopses with Tags](https://www.kaggle.com/datasets/cryptexcode/mpst-movie-plot-synopses-with-tags)\n","\n","database_name = \"Wikipedia Movie Plots\" # @param [\"Wikipedia Movie Plots\", \"Crossed dataset\"]\n"],"metadata":{"id":"C81jvL4mEObE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Prétraitement des données"],"metadata":{"id":"Hft9wuWDVYyM"}},{"cell_type":"code","source":["# This function vectorizes the text in the dataframe using TF-IDF vectorization.\n","# It also creates a new feature by repeating the tags based on the length of 'plot_synopsis' and concatenating with the 'plot_synopsis'.\n","def vectorize_text(df, verbose=0):\n","  vectorizer = TfidfVectorizer(stop_words=\"english\")\n","  # Fit the vectorizer on the entire corpus\n","  vectorizer.fit(df['title'].tolist() + df['plot_synopsis'].tolist())\n","\n","  # Define a base multiplier : higher value = lower tag importance\n","  base_multiplier = 8\n","\n","  # Repeat the tags based on the length of 'plot_synopsis' and concatenate with the 'plot_synopsis'\n","  synopsis_with_tags = df.apply(lambda row: row['plot_synopsis'] + ' ' + (row['tags'] * (len(row['plot_synopsis'].split()) // base_multiplier)), axis=1)\n","\n","  df['title_vectorized'] = df['title'].apply(lambda x: vectorizer.transform([x]))\n","  df['plot_synopsis_vectorized'] = df['plot_synopsis'].apply(lambda x: vectorizer.transform([x]))\n","  df['plot_synopsis_with_tags_vectorized'] = synopsis_with_tags.apply(lambda x: vectorizer.transform([x]))\n","\n","  return df, vectorizer\n","\n","# This function shortens the plot of a movie to a specified number of characters or sentences.\n","# It uses a language model to generate a summary of the plot.\n","def summarize_shorten_plot(llm, movie_plot, nb_input_char=200, min_output_char=20, nb_output_sentences=2):\n","  s_prompt = \"[INST] Summarize the movie plot below with \"+str(nb_output_sentences)+\" sentences.\"\n","  e_prompt = \"[\\INST]\"\n","  if nb_input_char < 10:\n","    return llm(s_prompt+movie_plot+e_prompt)\n","  else:\n","    i = -1\n","    list_sentences = movie_plot.split(\"\\n\")\n","    while (-i < len(movie_plot)) and (len(\"\\n\".join(list_sentences[:i])) > nb_input_char):\n","      i -= 1\n","    if (-i < len(movie_plot)) and (i >= min_output_char):\n","      new_plot = \"\\n\".join(list_sentences[:i])\n","    else:\n","      i = -1\n","      list_sentences = movie_plot.split(\".\")\n","      while (-i < len(movie_plot)) and (len(\".\".join(list_sentences[:i])) > nb_input_char):\n","        i -= 1\n","      if (-i < len(movie_plot))and (i >= min_output_char):\n","        new_plot = \".\".join(list_sentences[:i])\n","      else:\n","        new_plot = movie_plot[:nb_input_char-1]\n","        new_plot += \".\"\n","    return llm(s_prompt+new_plot+e_prompt)\n","\n","# This function prepares the Wikipedia dataset for use in the recommendation system.\n","# It extracts the relevant columns and renames them to match the expected format.\n","def treat_wiki(df_wiki):\n","  df = pd.DataFrame()\n","  df[\"title\"] = df_wiki[\"Title\"]\n","  df[\"plot_synopsis\"] = df_wiki[\"Plot\"]\n","  df[\"tags\"] = df_wiki[\"Genre\"]\n","  return df\n","\n","# This function merges and prepares the MPST and Wikipedia datasets for use in the recommendation system.\n","# It matches movies based on title, and uses a language model to generate a summary of the plot if necessary.\n","def treat_dataset(df_mpst, df_wiki, llm_summarizer=None, verbose=0):\n","  pretreated_df = pd.DataFrame(columns=[\"title\", \"plot_synopsis\", \"tags\"])\n","  i = 0\n","  size_df = df_mpst.shape[0]\n","  for row in df_mpst.values:\n","    search = df_wiki[row[1] == df_wiki[\"Title\"]]\n","    if search[\"Title\"].count() == 1:\n","      pretreated_df.loc[i] = {\n","          \"title\": str(row[1]),\n","          \"plot_synopsis\": str(search[\"Plot\"]),\n","          \"tags\": str(row[3])\n","      }\n","      i += 1\n","    elif (llm_summarizer != None) and (search[\"Title\"].count() < 1):\n","      # WARNING: This functionnality wasn't tested and might take a while to compute\n","      if verbose > 0:\n","        print(\"STEP \",i+1,\"/\",size_df,\": Summarizing the movie '\",row[1],\"'.\")\n","      pretreated_df.loc[i] = {\n","          \"title\": str(row[1]),\n","          \"plot_synopsis\": summarize_shorten_plot(llm_summarizer, search[\"Plot\"], nb_input_char=300),\n","          \"tags\": str(row[3])\n","      }\n","      i += 1\n","  return pretreated_df"],"metadata":{"id":"FxMeNpbOrysh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if database_name == \"Crossed dataset\":\n","  # 1) Generating a new dataset\n","  df = treat_dataset(get_mpst_dataset(), get_wiki_dataset())\n","  # 2) Vectorizing the text\n","  df, vectorizer = vectorize_text(df)\n","else:\n","  # 1) Generating a new dataset\n","  df = treat_wiki(get_wiki_dataset())\n","  # 2) Vectorizing the text\n","  df, vectorizer = vectorize_text(df)"],"metadata":{"id":"l0j9VNOVu8YE","colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"status":"error","timestamp":1702154409867,"user_tz":-60,"elapsed":158077,"user":{"displayName":"Damir Sagdullin","userId":"03847448103671542964"}},"outputId":"75912021-82d8-407d-e0a5-d72ec790f945"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-39eac905bef8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreat_wiki\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_wiki_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# 2) Vectorizing the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-08531d76b95c>\u001b[0m in \u001b[0;36mvectorize_text\u001b[0;34m(df, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_synopsis_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_synopsis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_synopsis_with_tags_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynopsis_with_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-15-08531d76b95c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_synopsis_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_synopsis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_synopsis_with_tags_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynopsis_with_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0;31m# does not work as usual and we need to specify the attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m             \u001b[0;31m# name:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"idf_\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"idf vector is not fitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0;31m# *= doesn't work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__sklearn_is_fitted__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__sklearn_is_fitted__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36midf_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;31m# if _idf_diag is not set, this will raise an attribute error,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0;31m# which means hasattr(self, \"idf_\") is False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idf_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# is in {None, -1, 0, 1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_spbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0msum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_spbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dimensions do not match\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \"\"\"\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collapse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m---> 48\u001b[0;31m          initial=_NoValue, where=True):\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["df"],"metadata":{"id":"pH_2AT4G_Lds"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ezncjqLKLUJM"},"source":["## Algorithme de recommandation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gfck4FtsVpmH"},"outputs":[],"source":["# Function to recommend a movie based on the dataset and the conversation\n","def content_based_recommendation(input, df, type, vectorizer, top_recommendation_history=[], verbose=0):\n","    extracted_title, user_sentence = input\n","    # If the type is 'title', we are looking for a specific movie title\n","    if type == 'title':\n","        if extracted_title in df['title'].values:\n","            if verbose: print(\"title in DB => by title\")\n","            # Get the vectorized plot synopsis with tags for the extracted title\n","            input_plot_synopsis_with_tags_vectorized = df[df['title'] == extracted_title]['plot_synopsis_with_tags_vectorized'].values[0]\n","        else:\n","            extracted_title_vectorized = vectorizer.transform([extracted_title])\n","            similarity_scores = cosine_similarity(vstack(df['title_vectorized'].tolist()), extracted_title_vectorized)\n","            max_similarity_index = np.argmax(similarity_scores)\n","            max_similarity_score = similarity_scores[max_similarity_index]\n","            if max_similarity_score > 0.9:\n","                extracted_title = df.iloc[max_similarity_index]['title']\n","                if verbose: print(\"very close title in DB \"+extracted_title+\"=> by title\")\n","                # Get the vectorized plot synopsis with tags for the matched title\n","                input_plot_synopsis_with_tags_vectorized = df[df['title'] == extracted_title]['plot_synopsis_with_tags_vectorized'].values[0]\n","            else:\n","                if verbose: print(\"title not in DB => by synopsis\")\n","                # If no match is found, vectorize the user sentence instead\n","                input_plot_synopsis_with_tags_vectorized = vectorizer.transform([user_sentence])\n","    # If the type is 'synopsis', we are looking for a movie based on a plot synopsis\n","    elif type == 'synopsis':\n","        input_plot_synopsis_with_tags_vectorized = vectorizer.transform([user_sentence])\n","\n","    similarity_scores = cosine_similarity(vstack(df['plot_synopsis_with_tags_vectorized'].tolist()), input_plot_synopsis_with_tags_vectorized)\n","    sorted_similarity_scores_and_titles = sorted([(score, title) for score, title in zip(similarity_scores, df['title'])], key=lambda x: x[0], reverse=True)\n","    # Get the title of the most similar movie that has not been recommended before\n","    recommended_title = next((title for score, title in sorted_similarity_scores_and_titles if title not in top_recommendation_history), None)\n","    # Add the recommended title to the history\n","    top_recommendation_history.append(recommended_title)\n","\n","    if recommended_title is None:\n","        return \"NONE\"\n","    else:\n","        # Otherwise, get the plot synopsis of the recommended movie\n","        selected_synopsis = df[df['title'] == recommended_title]['plot_synopsis'].values[0]\n","        return recommended_title, selected_synopsis, top_recommendation_history"]},{"cell_type":"markdown","metadata":{"id":"fQXPDJ8gMvMH"},"source":["## Chatbot and Interface setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2_o4EI_MxfP"},"outputs":[],"source":["# Function to print on interface\n","def print_on_interface(interface_file, string):\n","    if interface_file != \"\":\n","        open(interface_file,\"a\").write(string)\n","    else:\n","        print(string)\n","\n","# Function to show interface\n","def show_interface(interface_file):\n","    if interface_file != \"\":\n","        output.clear()\n","        print(open(interface_file,'r').read())\n","\n","# Function to clear interface\n","def clear_interface(interface_file):\n","    if interface_file != \"\":\n","        try:\n","            file = open(interface_file,\"x\")\n","        except:\n","            file = open(interface_file,\"r+\")\n","        file.seek(0)\n","        file.truncate()\n","        file.close()\n","\n","# Function to shorten plot\n","def shorten_plot(movie_plot, nb_input_char=200, min_output_char=20):\n","  if nb_input_char > len(movie_plot):\n","    return movie_plot\n","  else:\n","    i = -1\n","    list_sentences = movie_plot.split(\"\\n\")\n","    while (-i < len(movie_plot)) and (len(\"\\n\".join(list_sentences[:i])) > nb_input_char):\n","      i -= 1\n","    if (-i < len(movie_plot)) and (i >= min_output_char):\n","      new_plot = \"\\n\".join(list_sentences[:i])\n","    else:\n","      i = -1\n","      list_sentences = movie_plot.split(\".\")\n","      while (-i < len(movie_plot)) and (len(\".\".join(list_sentences[:i])) > nb_input_char):\n","        i -= 1\n","      if (-i < len(movie_plot))and (i >= min_output_char):\n","        new_plot = \".\".join(list_sentences[:i])\n","      else:\n","        new_plot = movie_plot[:nb_input_char-1]\n","        new_plot += \".\"\n","    return new_plot\n","\n","# Function to recommend movie\n","def recommend_movie(llm, sentence, instruction, dt, discussion=\"\", verbose=0, top_recommendation_history = []):\n","    extracted_title = extract_movie_name(llm, sentence, verbose=verbose)\n","    type = 'title' if extracted_title != \"NONE\" else 'synopsis'\n","    output = content_based_recommendation([extracted_title, sentence], dt, type, vectorizer, top_recommendation_history, verbose = verbose)\n","    if output != \"NONE\":\n","      recommended_title, selected_synopsis, top_recommendation_history = output\n","      instruction = \"[INST] The following is a conversation with an AI that recommends movies. The agent should politely recommend the movie \"+recommended_title+\" and summerize the following synopsis in at most 4 sentences : \"+selected_synopsis+\". [\\INST]\\n\"\n","    line = \"Customer: \"+sentence+\"\\nAgent: \"\n","    try:\n","      return llm(instruction+discussion+line), top_recommendation_history\n","    except ValueError:\n","      instruction = \"[INST] The following is a conversation with an AI that recommends movies. The agent should politely recommend the movie \"+recommended_title+\" and summerize the following synopsis in at most 4 sentences : \"\n","      instruction += shorten_plot(selected_synopsis,nb_input_char=1000)+\". [\\INST]\\n\"\n","      return llm(instruction+discussion+line), top_recommendation_history\n","\n","# Function to pretreat answer\n","def posttreat_answer(answer, verbose=0):\n","  if verbose!=0:\n","    print(answer)\n","  answer = answer.split(\"\\n\")\n","  i=0\n","  while (i<len(answer)) and (answer[i]==\"\"):\n","    i += 1\n","  if (i<len(answer)):\n","    return answer[i]\n","  return \"ERROR\"\n","\n","# Function for recommendation chatbot\n","def recommendation_chatbot(llm, verbose=0):\n","  if verbose < 1:\n","    interface_file = \"artefact/conversation.txt\"\n","  else:\n","    interface_file = \"\"\n","  clear_interface(interface_file)\n","  instruction = \"\"\"\n","[INST] The following is a conversation with an AI that recommends movies. The agent should politely recommend a movie with its \"name\" and (genre). [\\INST]\n","\"\"\"\n","  print_on_interface(interface_file,\"\"\"-  DISCUSSION WITH CHATBOT -\n","\n","(Write 'STOP' to end the discussion with the chatbot.)\n","\n","\"\"\")\n","  print_on_interface(interface_file,\"YOU: \")\n","  show_interface(interface_file)\n","  user_input = str(input())\n","  print_on_interface(interface_file,user_input+\"\\n\")\n","  show_interface(interface_file)\n","  top_recommendation_history = []\n","  while user_input != \"STOP\":\n","    if sentence_about_movie(llm, user_input, verbose):\n","      llm_output, top_recommendation_history = recommend_movie(llm, user_input, instruction, df, verbose=verbose, top_recommendation_history = top_recommendation_history)\n","    else:\n","      line = \"\\nCustomer: \"+user_input+\"\\nAgent: \"\n","      reminder_instruction = \"\"\"\n","[INST] The following is a conversation with an AI that recommends movies. Customer entered irrelevant input. Remind to the customer your function.  [\\INST]\n","\"\"\"\n","      llm_output = llm(reminder_instruction+line)\n","    bot_answer = posttreat_answer(llm_output, verbose)\n","    print_on_interface(interface_file,\"BOT: \"+bot_answer+\"\\n\")\n","    print_on_interface(interface_file,\"\\nYOU: \")\n","    show_interface(interface_file)\n","    user_input = str(input())\n","    print_on_interface(interface_file,user_input+\"\\n\")\n","    show_interface(interface_file)\n","  print_on_interface(interface_file,\"\\n-  END OF DISCUSSION -\")\n","  show_interface(interface_file)\n","\n","# Function for recommendation chatbot with memory\n","def recommendation_chatbot_memory(llm, verbose=0):\n","  if verbose < 1:\n","    interface_file = \"artefact/conversation.txt\"\n","  else:\n","    interface_file = \"\"\n","  clear_interface(interface_file)\n","  instruction = \"\"\"\n","[INST] The following is a conversation with an AI that recommends movies. The agent should politely recommend a movie with its \"name\" and (genre). [\\INST]\n","\"\"\"\n","  print_on_interface(interface_file,\"\"\"-  DISCUSSION WITH CHATBOT -\n","\n","(Write 'STOP' to end the discussion with the chatbot.)\n","\n","\"\"\")\n","  discussion = \"\"\n","  print_on_interface(interface_file,\"YOU: \")\n","  show_interface(interface_file)\n","  user_input = str(input())\n","  print_on_interface(interface_file,user_input+\"\\n\")\n","  show_interface(interface_file)\n","  top_recommendation_history = []\n","  while user_input != \"STOP\":\n","    line = \"\\nCustomer: \"+user_input+\"\\nAgent: \"\n","    if sentence_about_movie(llm, user_input, verbose):\n","      llm_output, top_recommendation_history = recommend_movie(llm, user_input, instruction, df, verbose=verbose, top_recommendation_history = top_recommendation_history, discussion = discussion)\n","    else:\n","      reminder_instruction = \"\"\"\n","[INST] The following is a conversation with an AI that recommends movies. Customer entered irrelevant input. Remind to the customer your function.  [\\INST]\n","\"\"\"\n","      llm_output = llm(reminder_instruction+discussion+line)\n","    bot_answer = posttreat_answer(llm_output, verbose)\n","    print_on_interface(interface_file,\"BOT: \"+bot_answer+\"\\n\")\n","    discussion = line+bot_answer\n","    print_on_interface(interface_file,\"\\nYOU: \")\n","    show_interface(interface_file)\n","    user_input = str(input())\n","    print_on_interface(interface_file,user_input+\"\\n\")\n","    show_interface(interface_file)\n","  print_on_interface(interface_file,\"\\n-  END OF DISCUSSION -\")\n","  show_interface(interface_file)"]},{"cell_type":"markdown","source":["## Chatbot"],"metadata":{"id":"sqyMYZxg8az6"}},{"cell_type":"code","source":["# The function does not keep any memory of past messages.\n","# Each user input is processed independently, and the response is generated based solely on that input.\n","# This means that the chatbot does not have the ability to maintain context or remember past interactions.\n","recommendation_chatbot(llm, verbose=1)"],"metadata":{"id":"N3rkox9Z8n5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This function is more sophisticated than recommendation_chatbot because it can maintain context over multiple turns of conversation.\n","# This can lead to more relevant and coherent responses when the user's inputs are related to each other.\n","recommendation_chatbot_memory(llm, verbose=0)"],"metadata":{"id":"-U5WTgsw-R95"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["FU2PUo459uTW","-eU_-j6hp2oN","ZYeRYPfKs436","-uu_Oakos439","6eJCrwges43_"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"63f3348dafb84460a03558123c51d4e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d891231cb5d5417d93a249efdc9830aa","IPY_MODEL_9ba132accc0d46708dc215ce6617a76a","IPY_MODEL_70573587594c4d1ca5d0db1bcd13fab1"],"layout":"IPY_MODEL_13ae72d9df6c47339bd8f47196134c41"}},"d891231cb5d5417d93a249efdc9830aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_089c77e51122403493e87d503b1b15aa","placeholder":"​","style":"IPY_MODEL_11a0e9a8c6e240fe81015c4288199fb3","value":"mistral-moviechatbot-q5_K_M.gguf: 100%"}},"9ba132accc0d46708dc215ce6617a76a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90ad1adec10d439ba0809cdc265660f5","max":5131409056,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fdce08d340a4eaf940e5797a1203bb1","value":5131409056}},"70573587594c4d1ca5d0db1bcd13fab1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60bbe07ec81e422f97a71e55801de414","placeholder":"​","style":"IPY_MODEL_cecb38958359472f8aa7680588c14a2d","value":" 5.13G/5.13G [00:47&lt;00:00, 74.7MB/s]"}},"13ae72d9df6c47339bd8f47196134c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089c77e51122403493e87d503b1b15aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11a0e9a8c6e240fe81015c4288199fb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90ad1adec10d439ba0809cdc265660f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fdce08d340a4eaf940e5797a1203bb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60bbe07ec81e422f97a71e55801de414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cecb38958359472f8aa7680588c14a2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}